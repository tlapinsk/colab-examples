{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gans_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwZROro5aD69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "8c18ae31-8c0e-4c41-ef54-8b2f709f14ce"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Reshape\n",
        "from keras.layers import Conv2D, UpSampling2D\n",
        "from keras.layers import LeakyReLU, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output, Image\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMM9WB13Ruoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend.tensorflow_backend as ktf\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "def get_session(gpu_fraction=0.45):\n",
        "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
        "\n",
        "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
        "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
        "\n",
        "    if num_threads:\n",
        "        return tf.Session(config=tf.ConfigProto(\n",
        "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
        "    else:\n",
        "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "\n",
        "ktf.set_session(get_session())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAVIUMVwRwAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator():\n",
        "    \n",
        "    net = Sequential()\n",
        "    input_shape = (28, 28, 1)\n",
        "    dropout_prob = 0.4\n",
        "\n",
        "    net.add(Conv2D(64, 5, strides=2, input_shape=input_shape, padding='same'))\n",
        "    net.add(LeakyReLU())\n",
        "    \n",
        "    net.add(Conv2D(128, 5, strides=2, padding='same'))\n",
        "    net.add(LeakyReLU())\n",
        "    net.add(Dropout(dropout_prob))\n",
        "    \n",
        "    net.add(Conv2D(256, 5, strides=2, padding='same'))\n",
        "    net.add(LeakyReLU())\n",
        "    net.add(Dropout(dropout_prob))\n",
        "    \n",
        "    net.add(Conv2D(512, 5, strides=1, padding='same'))\n",
        "    net.add(LeakyReLU())\n",
        "    net.add(Dropout(dropout_prob))\n",
        "    \n",
        "    net.add(Flatten())\n",
        "    net.add(Dense(1))\n",
        "    net.add(Activation('sigmoid'))\n",
        "    \n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ToassMdR90d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "b7d2aae6-f35a-4a0e-88ab-c93c30cff134"
      },
      "source": [
        "net_discriminator = discriminator()\n",
        "net_discriminator.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 8193      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 4,311,553\n",
            "Trainable params: 4,311,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZAnpaZ6S3Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def generator():\n",
        "    \n",
        "    net = Sequential()\n",
        "    dropout_prob = 0.4\n",
        "    \n",
        "    net.add(Dense(7*7*256, input_dim=100))\n",
        "    net.add(BatchNormalization(momentum=0.9))\n",
        "    net.add(LeakyReLU())\n",
        "    net.add(Reshape((7,7,256)))\n",
        "    net.add(Dropout(dropout_prob))\n",
        "    \n",
        "    net.add(UpSampling2D())\n",
        "    net.add(Conv2D(128, 5, padding='same'))\n",
        "    net.add(BatchNormalization(momentum=0.9))\n",
        "    net.add(LeakyReLU())\n",
        "    \n",
        "    net.add(UpSampling2D())\n",
        "    net.add(Conv2D(64, 5, padding='same'))\n",
        "    net.add(BatchNormalization(momentum=0.9))\n",
        "    net.add(LeakyReLU())\n",
        "    \n",
        "    net.add(Conv2D(32, 5, padding='same'))\n",
        "    net.add(BatchNormalization(momentum=0.9))\n",
        "    net.add(LeakyReLU())\n",
        "    \n",
        "    net.add(Conv2D(1, 5, padding='same'))\n",
        "    net.add(Activation('sigmoid'))\n",
        "    \n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb9sI1j6S5qd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "855783e7-6925-4b72-cf10-27f0ead0aca1"
      },
      "source": [
        "net_generator = generator()\n",
        "net_generator.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 12544)             1266944   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 128)       819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 32)        51232     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 1)         801       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 2,394,241\n",
            "Trainable params: 2,368,705\n",
            "Non-trainable params: 25,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C221OA3YTIFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "81dbd9ba-98cd-4814-85f2-2bbd2924af15"
      },
      "source": [
        "optim_discriminator = RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-10)\n",
        "model_discriminator = Sequential()\n",
        "model_discriminator.add(net_discriminator)\n",
        "model_discriminator.compile(loss='binary_crossentropy', optimizer=optim_discriminator, metrics=['accuracy'])\n",
        "\n",
        "model_discriminator.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_1 (Sequential)    (None, 1)                 4311553   \n",
            "=================================================================\n",
            "Total params: 4,311,553\n",
            "Trainable params: 4,311,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN5skGaqTS6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "bbfbc826-1a19-47db-9402-ad208f8cc795"
      },
      "source": [
        "optim_adversarial = Adam(lr=0.0004, clipvalue=1.0, decay=1e-10)\n",
        "model_adversarial = Sequential()\n",
        "model_adversarial.add(net_generator)\n",
        "\n",
        "# Disable layers in discriminator\n",
        "for layer in net_discriminator.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_adversarial.add(net_discriminator)\n",
        "model_adversarial.compile(loss='binary_crossentropy', optimizer=optim_adversarial, metrics=['accuracy'])\n",
        "\n",
        "model_adversarial.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_2 (Sequential)    (None, 28, 28, 1)         2394241   \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 1)                 4311553   \n",
            "=================================================================\n",
            "Total params: 6,705,794\n",
            "Trainable params: 2,368,705\n",
            "Non-trainable params: 4,337,089\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wRaWL15TXAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "e9e363c1-ad0e-4942-8097-4557114464d6"
      },
      "source": [
        "# Read MNIST data\n",
        "x_train = input_data.read_data_sets(\"mnist\", one_hot=True).train.images\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype(np.float32)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-83305a6956df>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqVTPwhXjuKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "vis_noise = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "\n",
        "loss_adv = []\n",
        "loss_dis = []\n",
        "acc_adv = []\n",
        "acc_dis = []\n",
        "plot_iteration = []\n",
        "\n",
        "for i in range(10001):\n",
        "    \n",
        "    # Select a random set of training images from the mnist dataset\n",
        "    images_train = x_train[np.random.randint(0, x_train.shape[0], size=batch_size), :, :, :]\n",
        "    # Generate a random noise vector\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
        "    # Use the generator to create fake images from the noise vector\n",
        "    images_fake = net_generator.predict(noise)\n",
        "    \n",
        "    # Create a dataset with fake and real images\n",
        "    x = np.concatenate((images_train, images_fake))\n",
        "    y = np.ones([2*batch_size, 1])\n",
        "    y[batch_size:, :] = 0 \n",
        "\n",
        "    # Train discriminator for one batch\n",
        "    d_stats = model_discriminator.train_on_batch(x, y)\n",
        "    \n",
        "    # Train the generator\n",
        "    # The input of th adversarial model is a list of noise vectors. The generator is 'good' if the discriminator classifies\n",
        "    # all the generated images as real. Therefore, the desired output is a list of all ones.\n",
        "    y = np.ones([batch_size, 1])\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
        "    a_stats = model_adversarial.train_on_batch(noise, y)\n",
        "        \n",
        "    if i % 50 == 0:\n",
        "        plot_iteration.append(i)\n",
        "        loss_adv.append(a_stats[0])\n",
        "        loss_dis.append(d_stats[0])\n",
        "        acc_adv.append(a_stats[1])\n",
        "        acc_dis.append(d_stats[1])\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        fig, (ax1, ax2) = plt.subplots(1,2)\n",
        "        fig.set_size_inches(16, 8)\n",
        "\n",
        "        ax1.plot(plot_iteration, loss_adv, label=\"loss adversarial\")\n",
        "        ax1.plot(plot_iteration, loss_dis, label=\"loss discriminator\")\n",
        "        ax1.set_ylim([0,5])\n",
        "        ax1.legend()\n",
        "\n",
        "        ax2.plot(plot_iteration, acc_adv, label=\"acc adversarial\")\n",
        "        ax2.plot(plot_iteration, acc_dis, label=\"acc discriminator\")\n",
        "        ax2.legend()\n",
        "\n",
        "        plt.show()\n",
        "       \n",
        "    # Optional, print losses instead of plotting with:\n",
        "    # print(\"{}: [Dis. loss: {:.4f}, acc: {:.4f}] [Gen. loss: {:.4f}, acc: {:.4f}]\".format(i, d_stats[0], d_stats[1], a_stats[0], a_stats[1]))\n",
        "\n",
        "    if i % 500 == 0:\n",
        "        # Visualize the performance of the generator by producing images from the test vector\n",
        "        images = net_generator.predict(vis_noise)\n",
        "        # Map back to original range\n",
        "        #images = (images + 1 ) * 0.5\n",
        "        plt.figure(figsize=(10,10))\n",
        "        \n",
        "        for im in range(images.shape[0]):\n",
        "            plt.subplot(4, 4, im+1)\n",
        "            image = images[im, :, :, :]\n",
        "            image = np.reshape(image, [28, 28])\n",
        "            \n",
        "            plt.imshow(image, cmap='gray')\n",
        "            plt.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(r'output/mnist-normal/{}.png'.format(i))\n",
        "        plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}